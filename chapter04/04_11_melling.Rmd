---
title: "ISLR Q4.11 - Predict High or Low mpg/Auto"
output:
  html_document:
    toc: true
    depth: 2      
---
[ISLR Home](../index.html)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question

In this problem, you will develop a model to predict whether a given car gets high or low gas mileage based on the Auto data set.

(a) Create a binary variable, mpg01, that contains a 1 if mpg contains a value above its median, and a 0 if mpg contains a value below its median. You can compute the median using the median() function. Note you may find it helpful to use the data.frame() function to create a single data set containing both mpg01 and the other Auto variables.

(b) Explore the data graphically in order to investigate the associ- ation between mpg01 and the other features. Which of the other features seem most likely to be useful in predicting mpg01? Scat- terplots and boxplots may be useful tools to answer this ques- tion. Describe your findings.

(c) Split the data into a training set and a test set.

(d) Perform LDA on the training data in order to predict mpg01 using the variables that seemed most associated with mpg01 in (b). What is the test error of the model obtained?

(e) Perform QDA on the training data in order to predict mpg01 using the variables that seemed most associated with mpg01 in (b). What is the test error of the model obtained?

(f) Perform logistic regression on the training data in order to pre- dict mpg01 using the variables that seemed most associated with mpg01 in (b). What is the test error of the model obtained?

(g) Perform KNN on the training data, with several values of K, in order to predict mpg01. Use only the variables that seemed most associated with mpg01 in (b). What test errors do you obtain? Which value of K seems to perform the best on this data set?

***

```{r message=FALSE, warning=FALSE}
library(ISLR)
library(MASS)
library(class) # knn
```


Column names
```{r}
names(Auto)
```


# 11a

(a) Create a binary variable, mpg01, that contains a 1 if mpg contains a value above its median, and a 0 if mpg contains a value below its median. You can compute the median using the median() function. Note you may find it helpful to use the data.frame() function to create a single data set containing both mpg01 and the other Auto variables.

***

Creating a mpg01 predictor that returns 1 if greater than median of mpg

Creating a vector that returns 1 if >= median(Auto$mpg) else 0
```{r}
mpg01 = rep(0, nrow(Auto))
mpg01[Auto$mpg >= median(Auto$mpg)] = 1

```

## Creating a new dataframe combining Auto and mpg01
```{r}
new.auto = data.frame(Auto, mpg01)
```


# 11b

(b) Explore the data graphically in order to investigate the associ- ation between mpg01 and the other features. Which of the other features seem most likely to be useful in predicting mpg01? Scat- terplots and boxplots may be useful tools to answer this ques- tion. Describe your findings

***

Graphically viewing the correlation of mpg01 with other predictors
pairs(new.auto)

Comments: There seems to be some association with horsepower, weight, acceleration, and possibly displacement. There is a distinction between values when mpg01 = 1 or mpg01 = 0.

## Boxplots

mpg01 by displacement, acceleration, horsepower, weight

```{r}
boxplot(displacement~mpg01,data=new.auto, xlab="MPG > Median", ylab="Displacement")
boxplot(acceleration~mpg01,data=new.auto, xlab="MPG > Median", ylab="Acceleration")
boxplot(horsepower~mpg01,data=new.auto, xlab="MPG > Median", ylab="Horsepower")
boxplot(weight~mpg01,data=new.auto, xlab="MPG > Median", ylab="Weight")
```

Comments: Based on the boxplots, acceleration might be hard to predict if mpg is higher than median. The values of acceleration are too close to tell apart.

# 11c

(c) Split the data into a training set and a test set.

***

Creating sample size for train data (80% of the data)
```{r}
set.seed(1)
sample.size = floor(0.8*nrow(new.auto))
```

```{r}
# Get random sample of indices for train data
train = sample(seq_len(nrow(new.auto)), size=sample.size)

# Creating the train and test data
train.data = new.auto[train,]
test.data = new.auto[-train, ]

# Creating responses for train and test
y.train = train.data$mpg01
y.test = test.data$mpg01
```


# 11d

(d) Perform LDA on the training data in order to predict mpg01 using the variables that seemed most associated with mpg01 in (b). What is the test error of the model obtained?

***

## LDA Model
```{r}
lda.fit = lda(mpg01 ~ displacement + horsepower + weight, data=new.auto, subset = train)
```


## Predicting mpg01 using the test data
```{r}
lda.pred = predict(lda.fit, test.data)
```

## Confusion Matrix
```{r}
lda.class = lda.pred$class
table(lda.class, y.test) 
```


## Calculating the test error rate
```{r}
mean(lda.class != y.test) # test error rate: 12.7%
```


# 11e

(e) Perform QDA on the training data in order to predict mpg01 using the variables that seemed most associated with mpg01 in (b). What is the test error of the model obtained?

***

## QDA Model
```{r}
qda.fit = qda(mpg01 ~ displacement + horsepower + weight, data=new.auto, subset = train)
```


## Predicting mpg01 using the test data
```{r}
qda.pred = predict(qda.fit, test.data)
```


## Confusion Matrix
```{r}
qda.class = qda.pred$class
table(qda.class, y.test)
```

## Calculating test error rate
```{r}
mean(qda.class != y.test) # test-error rate: 10.1%
```

# 11f

(f) Perform logistic regression on the training data in order to pre- dict mpg01 using the variables that seemed most associated with mpg01 in (b). What is the test error of the model obtained?

***

## Fitting data using LR
```{r}
lr.fit = glm(mpg01 ~ displacement + horsepower + weight, 
             data=new.auto, 
             subset = train,
             family=binomial)
```


## Predicting on test set
```{r}
lr.fit.probs = predict(lr.fit, test.data, type="response")
```


## Creating a prediction vector
```{r}
lr.fit.pred = rep(0, nrow(test.data))
lr.fit.pred[lr.fit.probs > .5] = 1
table(lr.fit.pred, y.test)
```

## Calculating test error rate
```{r}
mean(lr.fit.pred != y.test) # test-error rate: 6.33%
```


# 11g

(g) Perform KNN on the training data, with several values of K, in order to predict mpg01. Use only the variables that seemed most associated with mpg01 in (b). What test errors do you obtain? Which value of K seems to perform the best on this data set?

***

## Getting data ready for KNN

Extracting the predictors from training data
```{r}
train.X = cbind(train.data$displacement + train.data$horsepower + train.data$weight)
```

## Extracting the response from training data
```{r}
train.y = train.data$mpg01
```


## Extracting predictors from test set
```{r}
test.X = cbind(test.data$displacement + test.data$horsepower + test.data$weight)
```

## Scaling the data
```{r}
scaled.train.X = scale(train.X)
scaled.test.X = scale(test.X)
```

## KNN, k=1
```{r}
knn.pred.1 = knn(scaled.train.X, scaled.test.X, train.y, k=1)
```

### Calculating test error rate
```{r}
mean(y.test != knn.pred.1) # 15.1% (changed from 13.9% after scaling)
```

## KNN, k=3
```{r}
knn.pred.3 = knn(scaled.train.X, scaled.test.X, train.y, k=3)
```

### Calculating test error rate
```{r}
mean(y.test != knn.pred.3) # 12.7% (changed from 13.9% after scaling)
```


### KNN, k=5
```{r}
knn.pred.5 = knn(scaled.train.X, scaled.test.X, train.y, k=5)
```


### Calculating test error rate
```{r}
mean(y.test != knn.pred.5) # 10.1%
```


### KNN, k=10
```{r}
knn.pred.10 = knn(scaled.train.X, scaled.test.X, train.y, k=10)
```

### Calculating test error rate
```{r}
mean(y.test != knn.pred.10) # 10.1%
```

