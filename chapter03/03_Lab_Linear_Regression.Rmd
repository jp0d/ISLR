---
title: "ISLR Lab 03 - Linear Regression"
output:
  html_document:
    toc: true
    depth: 2  
---
[ISLR Home](../index.html)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
#install.packages("ggthemes")
#install.packages("car")
library(tidyverse)
library(ggthemes) # https://www.datanovia.com/en/blog/ggplot-themes-gallery/
```

p100
```{r message=FALSE, warning=FALSE}
setwd("../chapter03/")
#getwd()
library(MASS)
library(ISLR)
# install.packages("ISLR")
# data(package = "ISLR") # View included datasets
```

# Simple Linear Regression

- mdev = median value of owner-occupied homes in \$1000s
- lstat = lower status of the population (percent).

```{r}
names(Boston)
```

- lstat is the predictor (x)
- mdev is the response (Y)

$mdev = \beta_0 + \beta_1 (lstat)$

```{r}
lm.fit = lm(medv ~ lstat, data = Boston)


# Can attach a default dataframe then it's implied in many places
attach(Boston) 
lm.fit = lm(medv~lstat) # Prefer the first method with data = Boston

lm.fit # Show the coefficients
```
$$
 \beta_0 = 34.55 \\
 \beta_1 = -0.95
$$
## Model Summary
```{r}
summary(lm.fit)
```

```{r}
names(lm.fit)
```

## Coefficients

```{r}
coef(lm.fit)
```

## Predict

```{r}
# one line for each lstat, c(5,10,15)
predict(lm.fit, data.frame(lstat = c(5,10,15)), interval = "confidence") # Confidence Intervals

predict(lm.fit, data.frame(lstat = c(5,10,15)), interval = "prediction") # Prediction Intervals
```

## Plot Points and Regression Line
```{r}
plot(lstat, medv) # Plot points
abline(lm.fit) # Add Least Squares Regression Line

abline(lm.fit, lwd=3) # Line width
abline(lm.fit, lwd=3, col="red") # color
abline(lm.fit, col="red")
abline(lm.fit, pch=20) # Plot character
abline(lm.fit, pch="+") # Plot character
abline(lm.fit, pch=1:20) # Plot character
```

## Plot Analytics

- Residuals vs Fitted
- Q-Q Plot tells us if residuals are normal
- Scale-Location
- Residuals vs Leverage


```{r}
par(mfrow = c(2,2)) # 4 plots in same picture
plot(lm.fit) # 4 plots
```

### Residuals

```{r, out.width="75%"}
par(mfrow = c(1,1)) # Reset to 1 picture
plot(predict(lm.fit), residuals(lm.fit))
```

### rstudent

```{r, out.width="75%"}
plot(predict(lm.fit), rstudent(lm.fit))
```

### Largest Leverage Statistic

which.max() identifies the index of the largest element of a vector

```{r, out.width="75%"}
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit)) # Largest leverage statistic
```

# Multiple Linear Regression

p113

## medv ~ lstat + age

$mdev = \beta_{1} * lstat + \beta_2 age$

```{r}
lm.fit = lm(medv ~ lstat + age, data = Boston)
summary(lm.fit)
```

## medv ~ .

Use all the x's/parameters/features

```{r}
lm.fit = lm(medv ~ . , data = Boston) # Use all 13 independent variables
summary(lm.fit)
```

### R-Squared: $R^2$

```{r}
summary(lm.fit)$r.sq
```

### Sigma: $\sigma$

```{r}
summary(lm.fit)$sigma
```

## Variance Inflation Factors - VIF

```{r}
# install.packages("car")
library(car)
vif(lm.fit) # Variance inflation factors
```

Fit all features, excluding age

```{r}
lm.fit_no_age = lm(medv ~ . -age, data = Boston) # Use all 13 variables minus age
summary(lm.fit_no_age)
```

### Model Summary
```{r}
update(lm.fit, ~. -age) # Another way to remove age
summary(lm.fit)
```

## Interaction Terms

p115

lstat * age means ...

$mdev = \beta_0 + \beta_1 (lstat * age)$

```{r}
summary(lm(medv ~ lstat * age, data = Boston))
```

## Non-Linear Transformations of the Predictors

$mdev = \beta_0 + \beta_1 lstat + \beta_2 lstat^2$

#### Model Summary
```{r}
lm.fit2 = lm(medv ~ lstat + I(lstat^2))
summary(lm.fit2)
```

## ANOVA

```{r}
lm.fit = lm(medv ~ lstat)
anova(lm.fit, lm.fit2)
```

```{r}
par(mfrow = c(2,2)) # 4 plots in same picture
plot(lm.fit2) # 4 plots
```

## Polynomial Fit

5th degree polynomial fit

$mdev = \beta_0 + \beta_1 lstat + \beta_2 lstat^2 + \beta_3 lstat^3 + \beta_4 lstat^4 + \beta_5 lstat^5$

```{r}
lm.fit5 = lm(medv ~ poly(lstat,5)) # 5th degree fit
summary(lm.fit5)
```

## Log Transformation 

$mdev = \beta_0 + \beta_1 log(rm)$

```{r}
lm.fit_log = lm(medv ~ log(rm), data = Boston) # log transformation rooms
summary(lm.fit_log)
```

## Qualitative Predictors

p117

- https://stackoverflow.com/questions/40567421/asterisk-vs-colon-in-r-formulas
 
```{r}
names(Carseats)
```

```{r}
lm.fit <- lm(Sales ~ . + Income:Advertising + Price:Age, data = Carseats)
summary(lm.fit)
```

lm.fit <- lm(Sales ~ Income:Advertising + Price:Age, data = Carseats)

```{r}
summary(lm.fit)
```


```{r}
attach(Carseats) # Makes table look better
contrasts(ShelveLoc) # Return coding for dummy variables
#?contrasts
```

## Writing Functions

p119

```{r}
LoadLibrary=function() {
  library(MASS)
  library(ISLR)
  print("Libraries loaded")
}

LoadLibrary()
```