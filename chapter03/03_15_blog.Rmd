---
title: "ISLR Q3.15 - Predict per capita crime rate/Boston"
output:
  html_document:
    toc: true
    toc_depth: 2
---
[ISLR Home](../index.html)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question

This problem involves the Boston data set, which we saw in the lab for this chapter. We will now try to predict per capita crime rate using the other variables in this data set. In other words, per capita crime rate is the response, and the other variables are the predictors.

(a) For each predictor, fit a simple linear regression model to predict the response. Describe your results. In which of the models is there a statistically significant association between the predictor and the response? Create some plots to back up your assertions.

(b) Fit a multiple regression model to predict the response using all of the predictors. Describe your results. For which predictors can we reject the null hypothesis $H_0 : \beta_j = 0$?

(c) How do your results from (a) compare to your results from (b)? Create a plot displaying the univariate regression coefficients from (a) on the x-axis, and the multiple regression coefficients from (b) on the y-axis. That is, each predictor is displayed as a single point in the plot. Its coefficient in a simple linear regression model is shown on the x-axis, and its coefficient estimate in the multiple linear regression model is shown on the y-axis.

(d) Is there evidence of non-linear association between any of the predictors and the response? To answer this question, for each predictor X, fit a model of the form

$$Y = \beta_0 + \beta_1X + \beta_2 X^2 + \beta_3 X^3 + \epsilon$$

***

# Notes

I summarize some of what you need to know to better understand linear regression.

## Degrees of freedom
## Residual Standard Error - RSE
## Multiple and Adjusted R-squared
## F-statistic and its p-value

## Four Diagnostic Graphs

- Residuals vs Fitted
- Q-Q Quartile/Quartile plot tells us if residuals are normal
- Scale-Location
- Residuals vs Leverage (bottom right)

```{r message=FALSE, warning=FALSE}
library(MASS) # Boston
library(tidyverse)
```

Information on the Boston Housing data can be found [here](https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/Boston.html)

```{r}
attach(Boston) # Attaching the Boston dataset to workspace

lm.function = function(predictor) {
  
  fit1 <- lm(crim ~ predictor, data = Boston)
  #fit1$coefficients
  # names(fit1$coefficients) <- c('Intercept', predictor)
  return(summary(fit1))
}

# for (v in c(rm, age)) {
#   summary(lm(crim ~ v, data = Boston))
# }
# lm.function(rm)
```

# 15a Simple Linear Regression

Fit each feature one at a time and evaluate


## Model: $crim = \beta_0 + \beta_1 zn$

$crim = \beta_0 + \beta_1 zn$

### Model Summary
```{r}
lm.zn = lm(crim ~ zn, data = Boston)
summary(lm.zn)
```

Based on the p-value (5.51e-6), zn has a significant association with crim

### Diagnostic Plots

```{r}
par(mfrow = c(2,2))
plot(lm.zn)
```

## Model: $crim = \beta_0 + \beta_1 indus$

$crim = \beta_0 + \beta_1 indus$

```{r}
lm.indus = lm(crim ~ indus, data = Boston)
summary(lm.indus)
```

### Diagnostic Plot
```{r}
par(mfrow = c(2,2))
plot(lm.indus)
```

Based on the p-value (2e-16), indus has a significant association with crim

## Model: $crim = \beta_0 + \beta_1 chas$

$crim = \beta_0 + \beta_1 chas$

### Model Summary

```{r}
lm.chas = lm(crim ~ chas, data = Boston)
summary(lm.chas)
```

Based on the p-value (.209), chas does not have an association with crim


## Model: $crim = \beta_0 + \beta_1 nox$

$crim = \beta_0 + \beta_1 nox$

### Model Summary

```{r}
lm.nox = lm(crim ~ nox, data = Boston)
summary(lm.nox)
```

Based on the p-value (2e-16), nox has a significant association with crim

## Model: $crim = \beta_0 + \beta_1 rm$

$crim = \beta_0 + \beta_1 rm$

### Model Summary
```{r}
lm.rm = lm(crim ~ rm, data = Boston)
summary(lm.rm)
```

Based on the p-value (6.35e-7), rm has a significant association with crim

## Model: $crim = \beta_0 + \beta_1 age$

$crim = \beta_0 + \beta_1 age$

### Model Summary
```{r}
lm.age = lm(crim ~ age, data = Boston)
summary(lm.age)
```

Based on the p-value (2.85e-16), age has a significant association with crim

## Model: $crim = \beta_0 + \beta_1 dis$

$crim = \beta_0 + \beta_1 dis$

### Model Summary

```{r}
lm.dis = lm(crim ~ dis, data = Boston)
summary(lm.dis)
```

Based on the p-value (2e-16), dis has a significant association with crim

## Model: $crim = \beta_0 + \beta_1 rad$

$crim = \beta_0 + \beta_1 rad$

### Model Summary
```{r}
lm.rad = lm(crim ~ rad, data = Boston)
summary(lm.rad)
```

Based on the p-value (2e-16), rad has a significant association with crim

## Model: $crim = \beta_0 + \beta_1 tax$

### Model Summary

```{r}
lm.tax = lm(crim ~ tax, data = Boston)
summary(lm.tax)
```

Based on the p-value (2e-16), tax has a significant association with crim

## Model: $crim = \beta_0 + \beta_1 ptratio$

### Model Summary

```{r}
lm.ptratio = lm(crim ~ ptratio, data = Boston)
summary(lm.ptratio)
```

Based on the p-value (2.94e-11), ptratio has a significant association with crim

## Model: $crim = \beta_0 + \beta_1 black$

### Model Summary

```{r}
lm.black = lm(crim~black)
summary(lm.black)
```

## Model: $crim = \beta_0 + \beta_1 lstat$

```{r}
lm.lstat = lm(crim ~ lstat, data = Boston)
summary(lm.lstat)
```

Based on the p-value (2e-16), lstat has a significant association with crim

## Model: $crim = \beta_0 + \beta_1 medv$

### Model Summary

```{r}
lm.medv = lm(crim ~ medv, data = Boston)
summary(lm.medv)
```

Based on the p-value (2e-16), tax has a significant association with crim

## Diagnostic Plots

```{r}
par(mfrow = c(2,2))
plot(lm.indus)
plot(lm.chas)
plot(lm.nox)
plot(lm.rm)
plot(lm.age)
plot(lm.dis)
plot(lm.rad)
plot(lm.tax)
plot(lm.ptratio)
plot(lm.lstat)
plot(lm.medv)
```

# 15b Multiple Linear Regression

## Fitting on all independent variables

### Model Summary
```{r}
lm.all = lm(crim ~ ., data=Boston)
summary(lm.all)
```

Based on the MLR, only zn, dis, rad, black, and medv have a significant association with crim (p-value is below 0.05) which means we can reject the null hypothesis

# 15c

## Coefficients

```{r}
x = c(coefficients(lm.zn)[2],
      coefficients(lm.indus)[2],
      coefficients(lm.chas)[2],
      coefficients(lm.nox)[2],
      coefficients(lm.rm)[2],
      coefficients(lm.age)[2],
      coefficients(lm.dis)[2],
      coefficients(lm.rad)[2],
      coefficients(lm.tax)[2],
      coefficients(lm.ptratio)[2],
      coefficients(lm.black)[2],
      coefficients(lm.lstat)[2],
      coefficients(lm.medv)[2])
y = coefficients(lm.all)[2:14]
```

## Plot Coefficients
```{r}
par(mfrow = c(1,1)) # 1 plot
plot(x, y)
```

x$coeffients <-  c('Intercept', "RME")


# 15d Non-Linear Association

## Model: $crim = \beta_0 + \beta_1 (zn) + \beta_2 (zn)^2 + \beta_3 (zn)^3 + \epsilon$

crim ~ zn with 3rd degree polynomials

$crim = \beta_0 + \beta_1 (zn) + \beta_2 (zn)^2 + \beta_3 (zn)^3 + \epsilon$

```{r}
lm.poly.zn = lm(crim ~ zn + I(zn^2) + I(zn^3), data = Boston)
summary(lm.poly.zn)
```

Based on the p-values, zn does NOT have a non-linear association with crim

## Diagnostic Plots

```{r}
par(mfrow = c(2,2))
plot(lm.zn)
```

## Model: $crim = \beta_0 + \beta_1 (indus) + \beta_2 (indus)^2 + \beta_3 (indus)^3 + \epsilon$ 

crim ~ indus with 3rd degree polynomials

$crim = \beta_0 + \beta_1 (indus) + \beta_2 (indus)^2 + \beta_3 (indus)^3 + \epsilon$

#### Model Summary

```{r}
lm.poly.indus = lm(crim ~ indus + I(indus^2) + I(indus^3), data = Boston)
summary(lm.poly.indus)
```

Based on the p-values, indus SHOWS that it has a non-linear association with crim

## Model: $crim = \beta_0 + \beta_1 (chas) + \beta_2 (chas)^2 + \beta_3 (chas)^3 + \epsilon$


crim ~ chas with 3rd degree polynomials

$crim = \beta_0 + \beta_1 (chas) + \beta_2 (chas)^2 + \beta_3 (chas)^3 + \epsilon$

#### Model Summary
```{r}
lm.poly.chas = lm(crim ~ chas + I(chas^2) + I(chas^3), data = Boston)
summary(lm.poly.chas)

```

Since chas is a factor, squaring it does not affect it.

## Model: $crim = \beta_0 + \beta_1 (nox) + \beta_2 (nox)^2 + \beta_3 (nox)^3 + \epsilon$

crim ~ nox with 3rd degree polynomials

$crim = \beta_0 + \beta_1 (nox) + \beta_2 (nox)^2 + \beta_3 (nox)^3 + \epsilon$

#### Model Summary

```{r}
lm.poly.nox = lm(crim ~ nox + I(nox^2) + I(nox^3), data = Boston)
summary(lm.poly.nox)
```

Based on the p-values, nox SHOWS that it has a non-linear association with crim

## Model: $crim = \beta_0 + \beta_1 (rm) + \beta_2 (rm)^2 + \beta_3 (rm)^3$
 

Model: crim ~ rm with 3rd degree polynomials

#### Model Summary
```{r}
lm.poly.rm = lm(crim ~ rm + I(rm^2) + I(rm^3), data = Boston)
summary(lm.poly.rm)
```

Based on the p-value, rm does NOT have a non-linear association with crim

## Model: $crim = \beta_0 + \beta_1 (age) + \beta_2 (age)^2 + \beta_3 (age)^3$

Model: crim ~ age

#### Model Summary
```{r}
lm.poly.age = lm(crim ~ age + I(age^2) + I(age^3), data = Boston)
summary(lm.poly.age)
```

Based on the p-values, age SHOWS a non-linear association with crim

## Model: $crim = \beta_0 + \beta_1 (dis) + \beta_2 (dis)^2 + \beta_3 (dis)^3$

Model: crim ~ dis

#### Model Summary
```{r}
lm.poly.dis = lm(crim ~ dis + I(dis^2) + I(dis^3), data = Boston)
summary(lm.poly.dis)
```

Based on the p-values, dis SHOWS a non-linear association with crim

## Model: $crim = \beta_0 + \beta_1 (rad) + \beta_2 (rad)^2 + \beta_3 (rad)^3$

Model: crim ~ rad

#### Model Summary
```{r}
lm.poly.rad = lm(crim ~ rad + I(rad^2) + I(rad^3), data = Boston)
summary(lm.poly.rad)
```

Based on the p-value, rad does NOT have a non-linear association with crim

## Model: $crim = \beta_0 + \beta_1 (tax) + \beta_2 (tax)^2 + \beta_3 (tax)^3$

Model: crim ~ tax with 3rd degree polynomials

```{r}
lm.poly.tax = lm(crim ~ tax + I(tax^2) + I(tax^3), data = Boston)
summary(lm.poly.tax)
```

Based on the p-value, tax does NOT have a non-linear association with crim

## Model: $crim = \beta_0 + \beta_1 (ptratio) + \beta_2 (ptratio)^2 + \beta_3 (ptratio)^3$

Model: crim ~ ptratio 

#### Model Summary
```{r}
lm.poly.ptratio = lm(crim ~ ptratio + I(ptratio^2) + I(ptratio^3), data = Boston)
summary(lm.poly.ptratio)
```

Based on the p-value, ptratio SHOWS a non-linear association with crim

## Model: $crim = \beta_0 + \beta_1 (lstat) + \beta_2 (lstat)^2 + \beta_3 (lstat)^3$

Model: crim ~ lstat

#### Model Summary

```{r}
lm.poly.lstat = lm(crim ~ lstat + I(lstat^2) + I(lstat^3), data = Boston)
summary(lm.poly.lstat)
```

Based on the p-value, lstat NOT have a non-linear association with crim

## Model: $crim = \beta_0 + \beta_1 (medv) + \beta_2 (medv)^2 + \beta_3 (medv)^3$

Model: crim ~ medv

#### Model Summary

```{r}
lm.poly.medv = lm(crim ~ medv + I(medv^2) + I(medv^3), data = Boston)
summary(lm.poly.medv)
```

Based on the p-value, medv SHOWS a non-linear association with crim
