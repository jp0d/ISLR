---
title: "ISLR Q3.10"
output:
  html_document: default
---
[ISLR Home](../index.html)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This question should be answered using the Carseats data set.

```{r message=FALSE, warning=FALSE}
library(MASS)
library(ISLR)
```


## 10a

(a) Fit a multiple regression model to predict Sales using Price,
Urban, and US

***

```{r}
names(Carseats)
carseat.fit = lm(Sales ~ Price + Urban + US, data=Carseats)
```


## 10b

(b) Provide an interpretation of each coefficient in the model. Be
careful - some of the variables in the model are qualitative!

***

```{r}
summary(carseat.fit)
```

```{r}
contrasts(Carseats$US)
```

USYes coefficient: If the store is in the US (predictor=1), the sales increase 
at a rate ofthe coefficient is 1.2. 

sales = 1.2 * USYes (1.2 from coefficient from model) (ignoring other predictors for simplicity)

Price: Price is highly significant (p-value) when it comes to sales. There is a slight negative correlation to sales. As prices goes up, sales go down.

UrbanYes: Does not have a significant p-value. This means that it does not effect the sales.
Consider removing from model

## 10c

(c) Write out the model in equation form, being careful to handle the qualitative variables properly

***

Sales = 13.04 - 0.05 * Price + 1.2 * US
1 if US = Yes ; 0 if US = No

## 10d

(d) For which of the predictors can you reject the null hypothesis $$H_0 :\beta_j =0$$?

***

We can reject the null hypothesis for Price and USYes because its p-value is highly significant (<<.05)

## 10e

(e) On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome

***

```{r}
carseat.fit2 = lm(Sales ~ Price + US, data=Carseats)
summary(carseat.fit2)
```

```{r}
plot(carseat.fit2)
```

## 10f

(f) How well do the models in (a) and (e) fit the data?

***

The models for both (a) and (e) do NOT fit the data well. The R^2 statistic for both models show that the model ONLY explains 23% of the variance.  

## 10g

(g) Using the model from (e), obtain 95% confidence intervals for the coefficient(s).

***

Getting the confidence intervals for each coefficient confint(carseat.fit2)

## 10h

(h) Is there evidence of outliers or high leverage observations in the model from (e)?

***

Visualizing the statistics for leverage
```{r}
par(mfrow = c(2,2))
plot(carseat.fit2)
```

Based on the Residuals vs. Leverage graph (bottom right):

 - There is one observation that is far right of the graph. This means that its leverage is really high. Also there are few more that are few more that have high leverage.


