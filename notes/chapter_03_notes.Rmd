---
title: "ISLR Chapter 03 Notes - Linear Regression"
output:
  html_document:
    toc: true
    depth: 2    
---
[ISLR Home](../index.html)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Linear Regression

Machine Learning: Start with linear regression

“a very simple approach for supervised learning”

“widely used statistical learning method”

## House Prices

Square feet | Price 

$y = Mx + b$

Written as $y = \beta_0 + \beta_1x$

y is called response or target 
x predictor

Once we know betas we can predict value of response 

Minimize the total error from each point to our line. 

Bend the line to fit better 


Square feet | # bedrooms | Price 

cs229 Example 

Simple Linear one variable 

“We typically assume that the error term is independent of X.”


# Multiple Linear Regression
p71

We usually have more than one predictor. 

 $Y = \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p + \epsilon$

## Estimating the Coefficients

p72

 $\hat{y} = \hat{\beta}_0 + \beta_1 X_1 + \cdots + \beta_p X_p + \epsilon$

RSS = 

Choose $\beta$ to $\beta_p$ that minimizes RSS
p73
