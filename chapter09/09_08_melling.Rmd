---
title: "ISLR Q9.8 - Support Vector/OJ"
output:
  html_document:
    toc: true
    depth: 2           
---
[ISLR Home](../index.html)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question

p371

This problem involves the OJ data set which is part of the ISLR package.
Question 9 was the OJ problem in Chapter 8.

(a) Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations.

(b) Fit a support vector classifier to the training data using
cost=0.01, with Purchase as the response and the other variables as predictors. Use the summary() function to produce summary statistics, and describe the results obtained.

(c) What are the training and test error rates?

(d) Use the tune() function to select an optimal cost. Consider val-
ues in the range 0.01 to 10.

(e) Compute the training and test error rates using this new value
for cost.

(f) Repeat parts (b) through (e) using a support vector machine
with a radial kernel. Use the default value for gamma.

(g) Repeat parts (b) through (e) using a support vector machine
with a polynomial kernel. Set degree=2.

(h) Overall, which approach seems to give the best results on this data?

***

```{r message=FALSE, warning=FALSE, include=FALSE}
library(ISLR)
library(tidyverse)
library(e1071)
```

# 8a


Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations. (see Q8.9)

```{r, q8_9}
# From Q8.9
dim(OJ)
set.seed(1)
train = sample(1:nrow(OJ), 800)

# Don't actually use these ???
oj.train = OJ[train,]
oj.test = OJ[-train,]
oj.train.y = OJ[train,"Purchase"]
oj.test.y = OJ[-train,"Purchase"]
```

# 8b

Fit a support vector classifier to the training data using cost=0.01, with Purchase as the response and the other variables as predictors.

- Use the summary() function to produce summary statistics, 
- describe the results obtained.


Parameters: Cost = 0.01
```{r}
svm.fit = svm(Purchase ~ ., data = oj.train, kernel = "linear", cost = c(0.01))
summary(svm.fit)
```

# 8c

What are the training and test error rates?

## Training Data Confusion Matrix
```{r, 8c}
svm.predict = predict(svm.fit, newdata = oj.train)
result = table(true=oj.train.y, pred=svm.predict)
result
```
## Training Data Accuracy
```{r}
(result[1] + result[4]) / sum(result)
```


## Test Data Confusion Matrix
```{r}
svm.predict = predict(svm.fit, newdata = oj.test)
result = table(true=oj.test.y, pred=svm.predict)
result
```

## Test Data Accuracy
```{r}
(result[1] + result[4]) / sum(result)
```

# 8d Cross-Validation

Use the tune() function to select an optimal cost. Consider values in the range 0.01 to 10

```{r, 8d}
tune.out = tune(svm, as.factor(Purchase) ~ ., 
                data = oj.train,
                kernel = "linear", 
                ranges = list(cost = c(0.01, 0.1, 1, 5, 10)))
summary(tune.out)
```

## Best Model

```{r}
best.model <- tune.out$best.model
best.model
```

```{r}
best.model$cost
```


# 8e

Compute the training and test error rates using this new value for cost

Parameters: Cost = 0.1
```{r}
#svm.fit = svm(Purchase ~ ., data = oj.train, kernel = "linear", cost = best_model)
#summary(svm.fit)
```
```{r}
best.model.predict = predict(best.model, newdata=oj.train)
result = table(true=oj.train.y, pred=best.model.predict)
result
```

## Best Model Training Data Accuracy
```{r}
(result[1] + result[4]) / sum(result)
```

Training Data Confusion Matrix
```{r}
#svm.predict = predict(svm.fit, newdata = oj.train)
#table(true=oj.train.y, pred=svm.predict)
```
```{r}
#(422+246)/800
```
```{r}
#best.model.predict = predict(best.model, newdata=oj.test)
#result = table(true=oj.test.y, pred=best.model.predict)
#result
```

## Best Model Test Data Confusion Matrix

```{r}
best.model.predict = predict(best.model, newdata=oj.test)
result = table(true=oj.test.y, pred=best.model.predict)
result
```

## Accuracy
```{r}
(result[1] + result[4]) / sum(result)
```

```{r}
#svm.predict = predict(svm.fit, newdata = oj.test)
#table(true=oj.test.y, pred=svm.predict)
```

```{r}
#(155+71)/270
```

# 8f

Repeat parts (b) through (e) using a support vector machine with a radial kernel. Use the default value for gamma

## 8f-b

Parameters: Cost = 0.01
```{r}
svm.fit.radial = svm(Purchase ~ ., data = oj.train, kernel = "radial", cost = c(0.01))
#summary(svm.fit.radial)
```

## 8f-c

### Training Data Confusion Matrix
```{r}
svm.predict = predict(svm.fit.radial, newdata = oj.train)
table(true=oj.train.y, pred=svm.predict)
```
## 8f-d

```{r}
tune.out = tune(svm, as.factor(Purchase) ~ ., 
                data = oj.train,
                kernel = "radial", 
                ranges = list(cost = c(0.01, 0.1, 1, 5, 10)))
summary(tune.out)
```

## 8f-e

Parameters: Cost = 0.1
```{r}
svm.fit = svm(Purchase ~ ., data = oj.train, kernel = "radial", cost = c(0.1))
summary(svm.fit)
```

### Test Data Confusion Matrix
```{r}
svm.predict = predict(svm.fit, newdata = oj.test)
table(true=oj.test.y, pred=svm.predict)
```

# 8g

Repeat parts (b) through (e) using a support vector machine with a polynomial kernel. Set degree=2

## 8g-b

Parameters: Cost = 0.01
```{r}
degree <- 2
svm.fit.radial = svm(Purchase ~ ., data = oj.train, kernel = "polynomial", cost = c(0.01), degree=degree)
#summary(svm.fit.radial)
```

## 8g-c

### Training Data Confusion Matrix
```{r}
svm.predict = predict(svm.fit.radial, newdata = oj.train)
table(true=oj.train.y, pred=svm.predict)
```
## 8g-d

```{r}
tune.out = tune(svm, as.factor(Purchase) ~ ., 
                data = oj.train,
                kernel = "polynomial", 
                ranges = list(cost = c(0.01, 0.1, 1, 5, 10),
                              degree = degree))
summary(tune.out)
```

## 8g-e

Parameters: Cost = 0.1
```{r}
svm.fit = svm(Purchase ~ ., data = oj.train, kernel = "polynomial", cost = c(0.1), degree = degree)
summary(svm.fit)
```

### Test Data Confusion Matrix
```{r}
svm.predict = predict(svm.fit, newdata = oj.test)
table(true=oj.test.y, pred=svm.predict)
```

# 8h

Overall, which approach seems to give the best results on this data?

