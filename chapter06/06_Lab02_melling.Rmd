---
title: "ISLR Chater 06 Lab02 - "
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 6.6 Lab 2: Ridge Regression and the Lasso

pg 251

```{r}
library(ISLR)
Hitters=na.omit(Hitters) # Need this line

x=model.matrix(Salary~.,Hitters)[,-1] # -1 Removes Intercept, column 1 created by model.matrix
y=Hitters$Salary
```

```{r}
#install.packages("glmnet")
library(glmnet)
grid=10^seq(10,-2,length=100) # λ = 1010 to λ = 10^−2
ridge.mod=glmnet(x, y, alpha=0, lambda=grid) # alpha=0 means ridge, alpha=1 means Lasso
```

```{r}
#coef(ridge.mod)
2+2
```

```{r}
dim(coef(ridge.mod))
```

### p252

```{r}
ridge.mod$lambda[50] # Large lambda implies small coefficients
```

```{r}
coef(ridge.mod)[,50]
```

```{r}
sqrt(sum(coef(ridge.mod)[-1,50]^2)) # l2 norm
```

```{r}
# p252
ridge.mod$lambda [60] # Small lambda implies larger coefficients
```

```{r}
coef(ridge.mod)[,60]
```

```{r}
sqrt(sum(coef(ridge.mod)[-1,60]^2))
```

We can use the predict() function for a number of purposes. For instance, we can obtain the ridge regression coefficients for a new value of λ, say 50

```{r}
predict(ridge.mod,s=50,type="coefficients")[1:20,]
```

```{r}
# p253
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
```

WRONG ANSWER: 101037

```{r}
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
```

WRONG ANSWER: 193253

```{r}
mean((mean(y[train])-y.test)^2)
```

WRONG s is the sum value that the l2 norm must be less than? See page 220 in the book for the constraint equation

```{r}
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2)
```

```{r}
ridge.pred=predict(ridge.mod, s=0, newx=x[test,], exact=T)
mean((ridge.pred-y.test)^2)
```

```{r}
lm(y~x, subset=train)
predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]
```

```{r}
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
```

```{r}
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,]) mean((ridge.pred-y.test)^2)
```

```{r}
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:20,]
```

## The Lasso

p255

```{r}
lasso.mod=glmnet(x[train ,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)
```

```{r}
set.seed(1)
cv.out=cv.glmnet(x[train ,],y[train],alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod, s=bestlam, newx=x[test,])
mean((lasso.pred-y.test)^2)
```

``` {.python}
x = 1
print(f"test:{x}")
```
